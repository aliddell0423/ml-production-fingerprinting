{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35941299",
   "metadata": {},
   "source": [
    "# Production Fingerprinting — Diagnostics & Parameter Sweep (v3)\n",
    "Purpose-built for diagnostics and iteration on clustering and model performance.\n",
    "\n",
    "Includes clustering diagnostics, parameter sweep, ablation (baseline vs +clusters), threshold selection, and macro cell (`quick_diag`)."
   ]
  },
  {
   "cell_type": "code",
   "id": "5148e2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:09.257279Z",
     "start_time": "2025-11-15T21:31:09.254201Z"
    }
   },
   "source": [
    "# --- Setup & Config ---\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "RAW_DIR  = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE   = 0.25\n",
    "\n",
    "# Vectorization\n",
    "NGRAM_RANGE   = (1, 2)\n",
    "MIN_DF        = 1\n",
    "MAX_FEATURES  = 100_000\n",
    "svd_components = 100  # keep; later try 150\n",
    "\n",
    "\n",
    "# Clustering\n",
    "USE_HDBSCAN               = True\n",
    "HDBSCAN_MIN_CLUSTER_SIZE  = 10\n",
    "HDBSCAN_MIN_SAMPLES       = None  # or an int < min_cluster_size\n",
    "\n",
    "TOP_K_CLUSTERS            = 100\n",
    "\n",
    "print(\"Config loaded.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "5585c7bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:13.827232Z",
     "start_time": "2025-11-15T21:31:13.824472Z"
    }
   },
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "try:\n",
    "    import hdbscan\n",
    "    HDBSCAN_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    HDBSCAN_AVAILABLE = False\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    import warnings\n",
    "    warnings.warn(f\"hdbscan not available ({e}); falling back to DBSCAN.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "print(\"Imports OK. HDBSCAN_AVAILABLE =\", HDBSCAN_AVAILABLE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK. HDBSCAN_AVAILABLE = True\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "272edbba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:16.911617Z",
     "start_time": "2025-11-15T21:31:16.908155Z"
    }
   },
   "source": [
    "# --- Data helpers ---\n",
    "def load_raw_frames(raw_dir: Path):\n",
    "    wo = pd.read_csv(raw_dir / \"work_orders.csv\")\n",
    "    logs = pd.read_csv(raw_dir / \"logs.csv\")\n",
    "    sw = pd.read_csv(raw_dir / \"stopworks.csv\")\n",
    "    return wo, logs, sw\n",
    "\n",
    "def combine_text_per_wo(logs: pd.DataFrame, sw: pd.DataFrame) -> pd.DataFrame:\n",
    "    logs = logs.copy()\n",
    "    logs[\"text_piece\"] = logs[\"level\"].astype(str) + \" \" + logs[\"message\"].astype(str)\n",
    "    agg_logs = (\n",
    "        logs.groupby(\"work_order_id\")[\"text_piece\"]\n",
    "            .apply(lambda s: \"\\n\".join(s.tolist()))\n",
    "            .rename(\"logs_text\").reset_index()\n",
    "    )\n",
    "    if not sw.empty:\n",
    "        sw_agg = (\n",
    "            sw.groupby(\"work_order_id\")[\"note_text\"]\n",
    "              .apply(lambda s: \"\\n\".join(s.astype(str).tolist()))\n",
    "              .rename(\"stopworks_text\").reset_index()\n",
    "        )\n",
    "    else:\n",
    "        sw_agg = pd.DataFrame(columns=[\"work_order_id\", \"stopworks_text\"])\n",
    "\n",
    "    text_df = agg_logs.merge(sw_agg, on=\"work_order_id\", how=\"left\")\n",
    "    text_df[\"stopworks_text\"] = text_df[\"stopworks_text\"].fillna(\"\")\n",
    "    text_df[\"all_text\"] = (text_df[\"logs_text\"].astype(str) + \"\\n\" + text_df[\"stopworks_text\"].astype(str)).str.strip()\n",
    "    return text_df\n",
    "\n",
    "def basic_log_stats(logs: pd.DataFrame) -> pd.DataFrame:\n",
    "    cnt = logs.pivot_table(index=\"work_order_id\", columns=\"level\", values=\"message\", aggfunc=\"count\", fill_value=0)\n",
    "    cnt = cnt.add_prefix(\"logcnt_\").reset_index()\n",
    "    total = logs.groupby(\"work_order_id\")[\"message\"].size().rename(\"logcnt_total\").reset_index()\n",
    "    logs[\"msg_len\"] = logs[\"message\"].astype(str).str.len()\n",
    "    avg_len = logs.groupby(\"work_order_id\")[\"msg_len\"].mean().rename(\"loglen_avg\").reset_index()\n",
    "    return cnt.merge(total, on=\"work_order_id\", how=\"outer\").merge(avg_len, on=\"work_order_id\", how=\"outer\").fillna(0)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "0d12ae8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:20.381515Z",
     "start_time": "2025-11-15T21:31:20.377430Z"
    }
   },
   "source": [
    "# --- Vectorization & clustering ---\n",
    "def make_tfidf_matrix(texts: List[str], ngram_range=(1,2), min_df=2, max_features=100_000):\n",
    "    vect = TfidfVectorizer(\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_features=max_features,\n",
    "    )\n",
    "    X = vect.fit_transform(texts)\n",
    "    return X, vect\n",
    "\n",
    "def reduce_svd(X, n_components=100, random_state=42):\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n",
    "    Xr = svd.fit_transform(X)\n",
    "    return Xr, svd\n",
    "\n",
    "def cluster_texts_matrix(X, use_hdbscan=True, min_cluster_size=20, min_samples=None,\n",
    "                         selection='leaf', metric='euclidean'):\n",
    "    if use_hdbscan and HDBSCAN_AVAILABLE:\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            min_samples=min_samples,                 # try None first\n",
    "            metric=metric,                           # 'euclidean' on SVD; 'cosine' if using raw TF-IDF\n",
    "            cluster_selection_method=selection,      # 'leaf' gives more clusters\n",
    "            cluster_selection_epsilon=0.0,           # can tune >0 later\n",
    "            prediction_data=False,\n",
    "        )\n",
    "        labels = clusterer.fit_predict(X)\n",
    "        return labels, \"hdbscan\", clusterer\n",
    "    else:\n",
    "        from sklearn.cluster import DBSCAN\n",
    "        clusterer = DBSCAN(eps=0.8, min_samples=10, metric=\"euclidean\")\n",
    "        labels = clusterer.fit_predict(X if isinstance(X, np.ndarray) else X.toarray())\n",
    "        model_type = \"dbscan\"\n",
    "        model = clusterer\n",
    "    return labels, model_type, model\n",
    "\n",
    "def build_cluster_feature_frame(work_order_ids, labels, top_k=100, include_noise_flag=True):\n",
    "    df = pd.DataFrame({\"work_order_id\": work_order_ids, \"cluster\": labels})\n",
    "    freq = df[\"cluster\"].value_counts(dropna=False)\n",
    "    kept = [c for c in freq.index.tolist() if c != -1][:top_k]\n",
    "    pivot = (\n",
    "        df.assign(val=1)\n",
    "          .pivot_table(index=\"work_order_id\", columns=\"cluster\", values=\"val\", aggfunc=\"sum\", fill_value=0)\n",
    "          .reset_index()\n",
    "    )\n",
    "    if include_noise_flag:\n",
    "        saw_noise = (pivot.get(-1, 0) > 0).astype(int)\n",
    "        pivot[\"saw_noise\"] = saw_noise\n",
    "    cols = [\"work_order_id\"] + kept + ([-1] if -1 in pivot.columns else []) + ([\"saw_noise\"] if include_noise_flag else [])\n",
    "    pivot = pivot[[c for c in cols if c in pivot.columns]]\n",
    "    new_cols = {c: (f\"cl_{int(c)}\" if isinstance(c, (int,)) else c) for c in pivot.columns if c not in [\"work_order_id\",\"saw_noise\"]}\n",
    "    pivot = pivot.rename(columns=new_cols)\n",
    "    return pivot"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "86dacef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:40:03.066375Z",
     "start_time": "2025-11-15T21:40:03.061552Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# --- Feature assembly & preprocessors ---\n",
    "def build_tabular_features(wo: pd.DataFrame, logs: pd.DataFrame, include_log_stats=True):\n",
    "    base = wo.copy()\n",
    "    y = base[\"failure_label\"].astype(int).values\n",
    "    base = base.drop(columns=[\"failure_label\"])\n",
    "    if include_log_stats:\n",
    "        stats = basic_log_stats(logs)\n",
    "        base = base.merge(stats, on=\"work_order_id\", how=\"left\")\n",
    "        num_cols = base.select_dtypes(include=[np.number]).columns\n",
    "        base[num_cols] = base[num_cols].fillna(0)\n",
    "    return base, y\n",
    "\n",
    "def build_preprocessor(frame: pd.DataFrame):\n",
    "    base = frame.drop(columns=[\"work_order_id\", \"failure_label\"], errors=\"ignore\").copy()\n",
    "    cat_cols = base.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    num_cols = [c for c in base.columns if c not in cat_cols]\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "            (\"cat\", Pipeline(steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "            ]), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "def assemble_features(wo, logs, sw,\n",
    "                      ngram_range=(1,2), min_df=2, max_features=100_000,\n",
    "                      use_hdb=True, min_cluster_size=20, min_samples=None,\n",
    "                      svd_components=100, top_k_clusters=100, seed=42):\n",
    "    text_df = combine_text_per_wo(logs, sw)\n",
    "    X_text, tfidf = make_tfidf_matrix(\n",
    "        text_df[\"all_text\"].tolist(),\n",
    "        ngram_range=ngram_range, min_df=min_df, max_features=max_features\n",
    "    )\n",
    "    # after SVD\n",
    "    if svd_components:\n",
    "        X_input, svd = reduce_svd(X_text, n_components=svd_components, random_state=seed)\n",
    "        X_input = normalize(X_input)             # <-- IMPORTANT: row-normalize\n",
    "        labels, model_type, cluster_model = cluster_texts_matrix(\n",
    "            X_input, use_hdbscan=use_hdb, min_cluster_size=min_cluster_size,\n",
    "            min_samples=min_samples, selection='leaf', metric='euclidean'\n",
    "        )\n",
    "    else:\n",
    "        # If you ever cluster raw TF-IDF, use cosine metric\n",
    "        X_input = normalize(X_text)\n",
    "        labels, model_type, cluster_model = cluster_texts_matrix(\n",
    "            X_input, use_hdbscan=use_hdb, min_cluster_size=min_cluster_size,\n",
    "            min_samples=min_samples, selection='leaf', metric='cosine'\n",
    "        )\n",
    "\n",
    "    labels, model_type, cluster_model = cluster_texts_matrix(\n",
    "        X_input, use_hdbscan=use_hdb, min_cluster_size=min_cluster_size, min_samples=min_samples\n",
    "    )\n",
    "    cl_feats = build_cluster_feature_frame(text_df[\"work_order_id\"].tolist(), labels, top_k=top_k_clusters, include_noise_flag=True)\n",
    "    base_tab, y = build_tabular_features(wo, logs, include_log_stats=True)\n",
    "    merged = base_tab.merge(cl_feats, on=\"work_order_id\", how=\"left\").fillna(0)\n",
    "\n",
    "    # Save cluster assignments for diagnostics\n",
    "    assign_path = PROC_DIR / \"cluster_assignments.csv\"\n",
    "    pd.DataFrame({\"work_order_id\": text_df[\"work_order_id\"], \"cluster\": labels}).to_csv(assign_path, index=False)\n",
    "\n",
    "    meta = {\n",
    "        \"tfidf\": tfidf,\n",
    "        \"svd\": svd,\n",
    "        \"cluster_model\": cluster_model,\n",
    "        \"cluster_model_type\": model_type,\n",
    "        \"labels\": labels,\n",
    "        \"noise_rate\": float((pd.Series(labels) == -1).mean())\n",
    "    }\n",
    "    return merged, y, meta"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "a7599ebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:10:34.590367Z",
     "start_time": "2025-11-15T21:10:34.586718Z"
    }
   },
   "source": [
    "# --- Modeling & evaluation + Macro cell ---\n",
    "def split_xy(frame: pd.DataFrame, y: np.ndarray, test_size=0.25, seed=42):\n",
    "    keys = frame[\"work_order_id\"].values\n",
    "    X = frame.drop(columns=[\"work_order_id\"])\n",
    "    X_train, X_test, y_train, y_test, k_train, k_test = train_test_split(\n",
    "        X, y, keys, test_size=test_size, random_state=seed, stratify=y\n",
    "    )\n",
    "    return (X_train, y_train, k_train), (X_test, y_test, k_test)\n",
    "\n",
    "def make_rf(random_state=42):\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        max_depth=20,\n",
    "        min_samples_leaf=5,\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "    )\n",
    "\n",
    "def evaluate_binary(y_true, y_prob, threshold=None):\n",
    "    if threshold is None:\n",
    "        p, r, t = precision_recall_curve(y_true, y_prob)\n",
    "        f1 = 2*p*r/(p+r+1e-9)\n",
    "        i = np.nanargmax(f1)\n",
    "        threshold = t[i-1] if i>0 else 0.5\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    return {\n",
    "        \"threshold\": float(threshold),\n",
    "        \"roc_auc\": float(roc_auc_score(y_true, y_prob)),\n",
    "        \"pr_auc\": float(average_precision_score(y_true, y_prob)),\n",
    "        \"report\": classification_report(y_true, y_pred, digits=3)\n",
    "    }\n",
    "\n",
    "def quick_diag(name, pipe, X_test, y_test, feat_merged, labels_path=\"data/processed/cluster_assignments.csv\"):\n",
    "    prob = pipe.predict_proba(X_test)[:,1]\n",
    "    eval_best = evaluate_binary(y_test, prob, threshold=None)\n",
    "\n",
    "    # Cluster outcomes\n",
    "    assign = pd.read_csv(labels_path)\n",
    "    df = pd.DataFrame({\"work_order_id\": feat_merged[\"work_order_id\"], \"y\": feat_merged[\"failure_label\"].astype(int)})\n",
    "    tab = assign.merge(df, on=\"work_order_id\").groupby(\"cluster\").y.agg(['mean','count']).sort_values('mean', ascending=False)\n",
    "    noise_rate = (assign.cluster==-1).mean()\n",
    "\n",
    "    return {\n",
    "        \"Name\": name,\n",
    "        \"Noise_rate\": float(noise_rate),\n",
    "        \"ROC_AUC\": eval_best[\"roc_auc\"],\n",
    "        \"PR_AUC\": eval_best[\"pr_auc\"],\n",
    "        \"Best_threshold\": eval_best[\"threshold\"],\n",
    "        \"Report@BestF1\": eval_best[\"report\"],\n",
    "        \"Cluster_outcomes_head\": tab.head(10)\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "ce154021",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:57.637617Z",
     "start_time": "2025-11-15T21:31:56.917684Z"
    }
   },
   "source": [
    "# --- Load data & assemble features ---\n",
    "wo, logs, sw = load_raw_frames(RAW_DIR)\n",
    "feat_merged, y, meta = assemble_features(\n",
    "    wo, logs, sw,\n",
    "    ngram_range=NGRAM_RANGE, min_df=MIN_DF, max_features=MAX_FEATURES,\n",
    "    use_hdb=USE_HDBSCAN, min_cluster_size=HDBSCAN_MIN_CLUSTER_SIZE, min_samples=HDBSCAN_MIN_SAMPLES,\n",
    "    svd_components=None, top_k_clusters=TOP_K_CLUSTERS, seed=RANDOM_SEED\n",
    ")\n",
    "pd.DataFrame(feat_merged.assign(failure_label=y)).to_csv(PROC_DIR / \"features_merged_diag.csv\", index=False)\n",
    "print(\"Merged features:\", feat_merged.shape, \"| Noise rate:\", meta[\"noise_rate\"])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/case_studies_project/.venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged features: (4000, 16) | Noise rate: 0.8765\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "24a76eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:32:00.940938Z",
     "start_time": "2025-11-15T21:31:59.088349Z"
    }
   },
   "source": [
    "# Identify cluster feature columns\n",
    "cluster_cols = [c for c in feat_merged.columns if c.startswith(\"cl_\")]\n",
    "if not cluster_cols:\n",
    "    print(\"Warning: no cluster columns present. Consider lowering HDBSCAN_MIN_CLUSTER_SIZE or MIN_DF.\")\n",
    "\n",
    "# Baseline frame excludes cluster columns\n",
    "baseline_frame = feat_merged[[\"work_order_id\"] + [c for c in feat_merged.columns if c not in cluster_cols + [\"work_order_id\"]]]\n",
    "\n",
    "# Build preprocessors on feature-only frames (no labels)\n",
    "pre_base = build_preprocessor(baseline_frame)\n",
    "pre_full = build_preprocessor(feat_merged)\n",
    "\n",
    "def debug_pre_cols(frame, name):\n",
    "    base = frame.drop(columns=[\"work_order_id\", \"failure_label\"], errors=\"ignore\")\n",
    "    cat_cols = base.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    num_cols = [c for c in base.columns if c not in cat_cols]\n",
    "    print(f\"[{name}] num_cols({len(num_cols)}):\", num_cols[:8], \"...\")\n",
    "    print(f\"[{name}] cat_cols({len(cat_cols)}):\", cat_cols[:8], \"...\")\n",
    "\n",
    "debug_pre_cols(baseline_frame, \"baseline\")\n",
    "debug_pre_cols(feat_merged, \"full\")\n",
    "\n",
    "# Train/test splits\n",
    "(train_b, y_tr_b, _), (test_b, y_te_b, _) = split_xy(baseline_frame, y, test_size=TEST_SIZE, seed=RANDOM_SEED)\n",
    "(train_f, y_tr_f, _), (test_f, y_te_f, _) = split_xy(feat_merged, y, test_size=TEST_SIZE, seed=RANDOM_SEED)\n",
    "\n",
    "# Pipelines\n",
    "pipe_base = Pipeline([(\"prep\", pre_base), (\"rf\", make_rf(RANDOM_SEED))]).fit(train_b, y_tr_b)\n",
    "pipe_full = Pipeline([(\"prep\", pre_full), (\"rf\", make_rf(RANDOM_SEED))]).fit(train_f, y_tr_f)\n",
    "\n",
    "# Predict & evaluate\n",
    "prob_b = pipe_base.predict_proba(test_b)[:, 1]\n",
    "prob_f = pipe_full.predict_proba(test_f)[:, 1]\n",
    "\n",
    "diag_base = evaluate_binary(y_te_b, prob_b)\n",
    "diag_full = evaluate_binary(y_te_f, prob_f)\n",
    "\n",
    "print(\"=== Baseline ===\")\n",
    "print(f\"ROC-AUC: {diag_base['roc_auc']:.4f} | PR-AUC: {diag_base['pr_auc']:.4f}\")\n",
    "print(diag_base[\"report\"])\n",
    "\n",
    "print(\"=== +Clusters ===\")\n",
    "print(f\"ROC-AUC: {diag_full['roc_auc']:.4f} | PR-AUC: {diag_full['pr_auc']:.4f}\")\n",
    "print(diag_full[\"report\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[baseline] num_cols(6): ['logcnt_ERROR', 'logcnt_INFO', 'logcnt_WARN', 'logcnt_total', 'loglen_avg', 'saw_noise'] ...\n",
      "[baseline] cat_cols(6): ['catalog_id', 'supplier', 'device_type', 'technician', 'shift', 'build_date'] ...\n",
      "[full] num_cols(9): ['logcnt_ERROR', 'logcnt_INFO', 'logcnt_WARN', 'logcnt_total', 'loglen_avg', 'cl_0', 'cl_1', 'cl_-1'] ...\n",
      "[full] cat_cols(6): ['catalog_id', 'supplier', 'device_type', 'technician', 'shift', 'build_date'] ...\n",
      "=== Baseline ===\n",
      "ROC-AUC: 0.5656 | PR-AUC: 0.2107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.858     0.618     0.719       823\n",
      "           1      0.229     0.525     0.318       177\n",
      "\n",
      "    accuracy                          0.602      1000\n",
      "   macro avg      0.543     0.572     0.519      1000\n",
      "weighted avg      0.747     0.602     0.648      1000\n",
      "\n",
      "=== +Clusters ===\n",
      "ROC-AUC: 0.5643 | PR-AUC: 0.2107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.859     0.557     0.676       823\n",
      "           1      0.218     0.576     0.317       177\n",
      "\n",
      "    accuracy                          0.560      1000\n",
      "   macro avg      0.539     0.566     0.496      1000\n",
      "weighted avg      0.746     0.560     0.612      1000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "2ed12614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:32:09.865590Z",
     "start_time": "2025-11-15T21:32:09.796385Z"
    }
   },
   "source": [
    "# --- Macro usage example ---\n",
    "diag = quick_diag(\"current-config\", pipe_full, test_f, y_te_f, pd.DataFrame(feat_merged.assign(failure_label=y)))\n",
    "diag"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'current-config',\n",
       " 'Noise_rate': 0.8765,\n",
       " 'ROC_AUC': 0.5642509490564355,\n",
       " 'PR_AUC': 0.2107188339666781,\n",
       " 'Best_threshold': 0.43828886700591946,\n",
       " 'Report@BestF1': '              precision    recall  f1-score   support\\n\\n           0      0.859     0.557     0.676       823\\n           1      0.218     0.576     0.317       177\\n\\n    accuracy                          0.560      1000\\n   macro avg      0.539     0.566     0.496      1000\\nweighted avg      0.746     0.560     0.612      1000\\n',\n",
       " 'Cluster_outcomes_head':              mean  count\n",
       " cluster                 \n",
       "  0       0.198758    483\n",
       " -1       0.174843   3506\n",
       "  1       0.000000     11}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:47.073460Z",
     "start_time": "2025-11-15T21:31:47.071292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "import numpy as np\n",
    "\n",
    "def eval_with_precision_floor(y_true, y_prob, floor=0.35):\n",
    "    p, r, th = precision_recall_curve(y_true, y_prob)\n",
    "    ok = np.where(p[:-1] >= floor)[0]\n",
    "    if len(ok)==0:\n",
    "        print(\"No threshold meets the precision floor.\")\n",
    "        return None\n",
    "    i = ok[np.argmax(r[ok])]\n",
    "    t = th[i]\n",
    "    y_pred = (y_prob >= t).astype(int)\n",
    "    print(f\"Chosen threshold: {t:.3f} (precision≥{floor}) | P:{p[i]:.3f} R:{r[i]:.3f}\")\n",
    "    print(classification_report(y_true, y_pred, digits=3))\n",
    "    return t"
   ],
   "id": "5fd78b8f50e77dda",
   "outputs": [],
   "execution_count": 26
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
